# Methods

## Preparation of reads from fungal isolates for synthetic dataset

A mock dataset has been created to simulate scenarios where multiple fungal species are present in the same sample.
Using reads from the sequencing of 65 known fungal isolates, I was able to control the proportions of species in each simulated scenario.
These synthetically generated datasets aim provide insight into the limitations and sensitivity of this pipeline.
Supplemental Table \@ref(tab:samplesheet) provides the list of fungal species or strains and the number of raw reads available for the mock dataset.
The steps to generate and prepare reads for this synthetic dataset are outlined below.

### DNA extraction, amplification and sequencing

The genomic DNA of 65 fungal strains was extracted with the Qiagen DNeasy Plant mini kit.
The DNA was extracted from mycelia or spore material of each fungal isolate.
Partial SSU, full ITS region and partial LSU regions of each sample were amplified with primers NS5 (forward) and LR6 (reverse).
The amplicons were prepared with the Oxford Nanopore's Native Barcoding Kit 96 V14 (code SQK-NBD114.96, ONT).
Fungal samples plus a negative control were multiplexed and sequenced using the MinION R10.4 flow cell.

### Bioinformatics - Basecalling, trimming and filtering

The raw ONT data was basecalled and demultiplexed using Guppy v6.4.2 with the super-high accuracy model (dna_r10.4.1_e8.2_400bps_sup).
The mean read length of amplicons after basecalling was ~2.2 KB as seen in Figure \@ref(fig:rawReadQuality).

- [alt] Dorado: dna_r10.4.1_e8.2_400bps_sup@v4.1.0

Sequencing adapters were trimmed from raw basecalled reads using Dorado v0.6.1 with the '`--no-trim-primers`' option to avoid removing primer sequences.
Cutadapt v4.6 [@Cutadapt] has been used to select and trim primers from amplicons that contain both forward (NS5) and reverse primer (LR6) sequences.
Amplicons where both of these primer sequences could not be detected were excluded from the analysis.
Cutadapt was also used to re-orient reads that have been sequenced by the reverse strand ('`--revcomp`' option), making it easier to process by downstream tools (Figure \@ref(fig:filterTrimFlowchart))

The full ITS region of these reads was extracted using ITSxpress v2.0.1 [@Rivers2018] with default settings other than '`--single_end`' and '`--taxa Fungi`' options.
Chopper v0.7.0 [@DeCoster2023] was used to select reads of the full ITS region having a length between 300-6000bp and mean Phred quality score above Q20.
Chimeric reads were detected using VSEARCH's [@rognesVSEARCHVersatileOpen2016] denovo and reference based methods.
The database used for reference based chimera detection of full ITS sequence was the UNITE general release v9.0 (sh_general_release_dynamic_s_all_25.07.2023).

```{r filterTrimFlowchart, echo=FALSE, fig.align ='center', fig.cap = "The steps taken to prepare raw reads for mock scenarios. Boxes inticate trimming and filtering stages of the pipeline with and the software used is in paretheses."}
DiagrammeR::grViz("digraph {
  graph [layout = dot, label='Quality Filtering of Raw Reads', labelloc='tl', labeljust='l', rankdir = LR, fontsize='30']

  node [shape = rectangle, peripheries=2, fontsize='20']
  rec1 [label = 'Adapter trimming\n(dorado)']
  rec2 [label = 'Primer trimming\n(cutadapt)']
  rec3 [label = 'Barcode region extraction\n(ITSxpress)']
  rec4 [label = 'Quality filtering\n(chopper)']
    subgraph chimera {
    rank = same
    rec5 [label = 'Chimera filtering\n(vsearch)']
    node [shape = rectangle, peripheries=1]
    rec7 [label = 'UNITE DB']
    rec7 -> rec5;
  }

  node [shape = plaintext, peripheries=0]
  rec0 [label = 'Raw demultiplexed reads\nfastq']
  rec6 [label = 'Quality filtered\nfull ITS sequences']


  # edge definitions with the node IDs
  edge [ fontsize='20']
  rec0 -> rec1 -> rec2 -> rec3
  rec3 -> rec4 [ label = 'Full ITS']
  rec4 -> rec5 -> rec6
  }",
  height = 200)
```


### Sample selection and taxonomic naming validation

To ensure that taxonomic names were used consistently between the fungal isolate samples and the reference database, manual validation of each sample name was performed.
A search was conducted for the recorded species name of each sample in the 2024 UNITE reference database [@abarenkovFullUNITEINSDDataset2024; @vu_2024_12580255].
Most species names that could not be found were either misspelled or used an older taxonomic synonym.
For example, *Nakaseomyces glabratus* has been recorded by its former name *Candida glabrata* which the latter could not be found in the reference database.
Names of samples were manually updated using current names found in both Index Fungorum (www.indexfungorum.org) and the 2024 UNITE reference database.
For samples that were not classified at the species level (e.g. *Entoleuca sp* CCL052), the genus label was confirmed to exist in the reference database.

Seven samples that had less than a total of 2500 reads after basecalling, trimming and filtering were removed from the analysis leaving 58 samples (a total of 55 species).
The excluded taxa included: *Aspergillus niger*, *Naganishia albida* (*Cryptococcus albidus*), *Geotrichum candidum* (*Galactomyces geotrichum*), *Meyerozyma guilliermondii*, Yarrowia lipolytica, *Fusarium proliferatum* and *Puccinia recondita* (*Puccinia triticina*).
Bias in chimera detection leading to a loss 99.0% and 68.8% of reads in *Puccinia triticina* and  *Fusarium proliferatum* respectively.

### Synthetic dataset - Scenario 1 - Equal abundance

Four scenarios have been designed to test the pipeline under varying community structures. 
Each mock scenario consists of full ITS sequences that pass the quality filtering steps and are combined in different proportions to control the abundance of each sample.

Scenario 1 considers an even community structure where every fungal isolate has equal abundance (in terms of number of reads).
Libraries of differing sizes were generated by subsampling the same number of reads from each sample.
For each of the 58 samples: 20, 50, 167, 1000, 2000 and 2500 reads were randomly selected to produce libraries with sizes of 1160, 2900, 9686, 58000, 116000 and 145000 reads.
Seqtk v1.4 [@Lh3SeqtkToolkit] was used to perform the subsampling (with the '`sample`' command).
The subsampling was repeated five times for each library size producing a total of 30 libraries ($6 \text{ libraries} \times 5 \text{ repetitions}$).
The seed values given to seqtk's 'sample' command for each repetition were generated deterministically so that each run of the pipeline is reproducible.

### Synthetic dataset - Scenario 2 - Uneven (5 low abundance)

- 5 samples with very low, rest high
- selected samples randomly
- removed duplicate species
- 1/20, 1/10, 1/5, 2/5, 1/2

### Synthetic dataset - Scenario 3 - Uneven (5 high abundance)

- all very low, 5 high

### Synthetic dataset - Scenario 4 - Uneven (range of abundance)

- sampling in stepwise abundance increments

## Bioinformatics - Clustering

For each scenario full ITS sequences were grouped into approximate species-level clusters.
Two de-novo clustering approaches were explored and can be seen in Figure \@ref(fig:clusterAssignFlowchart).

The first approach uses centroid-based clustering on sequence similarity as implemented in VSEARCH [@rognesVSEARCHVersatileOpen2016].
The sequences were first de-replicated using VSEARCH's '--fastx_uniques' option to merge identical sequences into a single record, then clustered with the '--cluster_size' option.
A 97% identity was used as the pairwise sequence similarity threshold.
This clustering approach resulted in many low-abundance operational taxonomic units (OTUs), largely overestimating the number of species when unfiltered.
A minimum OTU size threshold of 0.1% of the library size was used to filter out low-abundance OTUs and more closely estimate the number of species (see Section \@ref(cluster-results) for the determination of this threshold).

The second approach clusters similar sequences through transformations of k-mer signatures as used in the NanoCLUST pipeline [@rodriguez-perezNanoCLUSTSpecieslevelAnalysis2021; @langsiriTargetedSequencingAnalysis2023].
Each sequence was transformed into a k-mer frequency vector and stored in a tabular format.
In our pipeline, 6-mer frequencies were computed (as opposed to 5-mers in NanoCLUST).
The multidimensional tabular structure was then projected into two-dimensions using Uniform Manifold Approximation and Projection (UMAP) [@mcinnesUMAPUniformManifold2020].
Sequences (represented as points in the two-dimensional space) were then clustered using Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) [@mcinnes2017hdbscan].
The 'cluster_selection_epsilon' parameter used in HDBSCAN was set to 0.5 as used in [@langsiriTargetedSequencingAnalysis2023], while the 'min_cluster_size' parameter was set to 0.5% of the library size.
See Section \@ref(cluster-results) for determination of the 'min_cluster_size' parameter.

```{r clusterAssignFlowchart, echo=FALSE, fig.align ='center', fig.cap = "Clustering stages of the pipeline with the tools used in paretheses."}
DiagrammeR::grViz("digraph {
  graph [layout = dot, label='Read Clustering', labelloc='tl', labeljust='l', rankdir = LR, fontsize='50']

  node [shape = rectangle, peripheries=1, fontsize='30', width=3.5]

  subgraph {
    subgraph A {
      derep [ label = 'Read dereplication\n(vsearch)' ]
      vsearch [ label = '97% identity clustering\n(vsearch)' ]
    }
    subgraph B {
      kmer [ label = 'k-mer frequencies\n(python)' ]
      umap [ label = 'Dimension reduction\n(UMAP)' ]
      hdbscan [ label = 'Clustering\n(HDBSCAN)' ]
    }
  }
  subgraph {
    rank = same
    mostA [ label = 'Most abundant sequence\n(vsearch)' ]
    consA [ label = 'Consensus sequence\n(polishing)' ]
    centr [ label = 'centroids\n(vsearch)' ]

  }

  node [shape = rectangle, peripheries=2]
  subs [label = 'Scenario 1\nEven abundance\n(6 libs, 5 reps)']

  node [shape = plaintext, peripheries=0]
  qc [label = 'Quality filtered\nfull ITS sequences']

  reps [label = 'Representative sequences\nfor classification' ]

  # edge definitions with the node IDs
  edge [ fontsize = '20']
  qc -> subs
  subs -> derep -> vsearch
  subs -> kmer -> umap -> hdbscan -> mostA
  hdbscan -> consA
  vsearch -> consA

  vsearch -> centr -> reps
  consA -> reps
  mostA -> reps
  #vsearch -> dnabarcoder [ label = 'centroids' ]
  #mostA -> dnabarcoder [ label = 'most abundant' ]
  #unite -> dnabarcoder
  }",
  height = 200)
```

## Bioinformatics - Taxonomic assignments

A representative sequence was selected from each cluster to provide a taxonomic assignment.
Our initial approach used the most abundant sequence of each cluster as the representative sequence.
The VSEARCH clustering approach provides the most abundant sequences with the '`--centroids`' option.
To determine the most abundant sequence from clusters in the UMAP + HDBSCAN approach, the VSEARCH '`--fastx_uniques`' command in combination with '`--topn 1`' option was used.

Alternatively, a consensus sequence was built from the reads from each cluster following a similar approach used by nanoCLUST see Figure \@ref(fig:clusterPolishFlow).
First a subset of 200 sequences was selected from each cluster to reduce computation time and space requirements.
Then a draft sequence was selected by taking the read with the highest Average Nucleotide Identity (ANI) to all the other sequences with FastANI [@jainHighThroughputANI2018].
Subsequently, the draft read underwent two rounds of polishing using Racon v1.5.0 [@vaserFastAccurateNovo2017] then Medaka v1.12.0 ([https://github.com/nanoporetech/medaka](https://github.com/nanoporetech/medaka)).
As Canu [@korenCanuScalableAccurate2017] is designed as a long-read assembler, it has a strict minimum genome size of 1000 making it unable to polish full ITS sequences from my dataset (which were around 400bp).

```{r clusterPolishFlow, echo=FALSE, fig.align ='center', fig.cap = "The process of producing a consensus sequences for each cluster by selecting and polishing a draft read. Tools used for each stage are in parentheses."}
DiagrammeR::grViz("digraph {
  graph [layout = dot, label='Consensus Sequence Polishing', labelloc='tl', labeljust='l', rankdir = LR, fontsize='50']

  node [shape = rectangle, peripheries=1, fontsize='30', width=3.5]

  subset [ label = 'Subset reads for polishing\n(n=200)' ]
  subgraph {
  fastANI [ label = 'Select draft by max ANI\n(fastANI)' ]
  racon [  label = 'Polish draft\n(racon)' ]
  medaka [ label = 'Polish draft\n(medaka)' ]
  }

  node [shape = plaintext, peripheries=0]
  reads [label = 'Set of reads in same cluster']
  reps [label = 'Representative sequences\nfor classification' ]

  # edge definitions with the node IDs
  edge [ fontsize = '20']
  reads -> subset -> fastANI -> racon -> medaka -> reps [ weight = 10 ]
  subset -> racon:nw
  subset -> medaka:nw
  }",
  height = 150)
```

The representative sequence from each cluster was then given a taxonomic assignment with dnabarcoder v1.0.6 [@vuDnabarcoderOpensourceSoftware2022].
In this case full ITS sequences were classified against the UNITE 2024 reference database [@abarenkovFullUNITEINSDDataset2024; @vu_2024_12580255] using precomputed similarity cutoffs provided by the dnabarcoder project (unite2024ITS.unique.cutoffs.best.json, @vuDnabarcoderOpensourceSoftware2022).